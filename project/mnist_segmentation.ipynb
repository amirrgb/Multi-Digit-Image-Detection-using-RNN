{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi again \n",
    "\n",
    "I know What to do now \n",
    "\n",
    "first let's Extract data and Store it in dataframe with label and images path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import os\n",
    "from skimage.filters import threshold_local\n",
    "from skimage.morphology import skeletonize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11719\n",
      "11719\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"./ORAND-CAR-2014/\"\n",
    "CAR_A_test_images_path = dir_path + 'CAR-A/a_test_images/'\n",
    "CAR_A_train_images_path = dir_path + 'CAR-A/a_train_images/'\n",
    "CAR_B_test_images_path = dir_path + 'CAR-B/b_test_images/'\n",
    "CAR_B_train_images_path = dir_path + 'CAR-B/b_train_images/'\n",
    "\n",
    "def load_original_images():\n",
    "    images_path = []\n",
    "    for root, dirs, files in os.walk(dir_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.png'):\n",
    "                image_path = os.path.join(root, file)\n",
    "                images_path.append(image_path.replace('\\\\','/'))\n",
    "    return images_path\n",
    "    \n",
    "images_path = load_original_images()\n",
    "\n",
    "def calculate_digit_count(label):\n",
    "    return len(label)\n",
    "\n",
    "def get_labels(image_dir,text_path):\n",
    "  with open(text_path,'r') as f :\n",
    "    lines = f.readlines()\n",
    "  listt = []\n",
    "  for line in lines :\n",
    "    parts = line.strip().split(\"\\t\")\n",
    "    listt.append([image_dir + parts[0],parts[1]])\n",
    "  DF = pd.DataFrame(listt)\n",
    "  DF = DF.rename(columns={0: 'image_path', 1: 'label'})\n",
    "  return DF\n",
    "\n",
    "def get_all_labels():\n",
    "  CAR_A_test_text = dir_path + 'CAR-A/a_test_gt.txt'\n",
    "  CAR_A_train_text = dir_path + 'CAR-A/a_train_gt.txt'\n",
    "  CAR_B_test_text = dir_path + 'CAR-B/b_test_gt.txt'\n",
    "  CAR_B_train_text = dir_path + 'CAR-B/b_train_gt.txt'\n",
    "  a_test_label_df = get_labels(CAR_A_test_images_path,CAR_A_test_text)\n",
    "  a_train_label_df = get_labels(CAR_A_train_images_path,CAR_A_train_text)\n",
    "  b_test_label_df = get_labels(CAR_B_test_images_path,CAR_B_test_text)\n",
    "  b_train_label_df = get_labels(CAR_B_train_images_path,CAR_B_train_text)\n",
    "  all_labels = pd.concat([a_test_label_df , a_train_label_df , b_test_label_df , b_train_label_df],ignore_index=True)#.reset_index()\n",
    "  return all_labels\n",
    "\n",
    "def reset_data():\n",
    "  all_labels = get_all_labels()\n",
    "  print(len(all_labels))\n",
    "  print(len(all_labels['image_path'].unique())) # no dupicate image name\n",
    "  all_labels[\"actual_digit_count\"] = all_labels[\"label\"].astype(str).apply(calculate_digit_count)\n",
    "  return all_labels\n",
    "\n",
    "all_labels = reset_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_dataFrame(all_labels):\n",
    "  height_list = []\n",
    "  width_list = []\n",
    "  for image_path in all_labels['image_path']:\n",
    "    height = Image.open(image_path).height\n",
    "    width = Image.open(image_path).width\n",
    "    \n",
    "    height_list.append(height)\n",
    "    width_list.append(width)\n",
    "\n",
    "  sizes_df = pd.DataFrame({'width':width_list,'height':height_list})\n",
    "  return sizes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's go for segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_image(image_label_df,from_path):\n",
    "    random.seed(42)\n",
    "    indices = list(range(len(image_label_df)))\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    for idx in indices[:10]+[21,22]:\n",
    "        target_image = image_label_df[from_path][idx]\n",
    "        print(\"label:\", image_label_df['label'][idx])\n",
    "        print(\"target:\", target_image)\n",
    "        image = mpimg.imread(target_image)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        time.sleep(2)\n",
    "        clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first converting to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_grayscale(df, from_path,new_dir_path):\n",
    "    try:\n",
    "        os.makedirs(new_dir_path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for i, img_path in enumerate(df[from_path]):\n",
    "        # Read the image in color (BGR format)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        # Convert the image to grayscale\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save the grayscale image\n",
    "        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n",
    "        cv2.imwrite(save_path, gray_img)\n",
    "\n",
    "    # Update the image paths in the DataFrame with the new grayscale image paths\n",
    "    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now denoising with GaussianBlur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_images(df, from_path, new_dir_path):\n",
    "    try:\n",
    "        os.makedirs(new_dir_path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for i, img_path in enumerate(df[from_path]):\n",
    "        # Read the image in grayscale\n",
    "        gray_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Apply Gaussian blur to denoise the image\n",
    "        denoised_image = cv2.GaussianBlur(gray_img, (5, 5), 0)\n",
    "\n",
    "        # Save the denoised image\n",
    "        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n",
    "        cv2.imwrite(save_path, denoised_image)\n",
    "\n",
    "    # Update the image paths in the DataFrame with the new denoised image paths\n",
    "    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### another denoise with cv2.fastNlMeansDenoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_images_fastnlmeans(df, from_path, new_dir_path):\n",
    "    try:\n",
    "        os.makedirs(new_dir_path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for i, img_path in enumerate(df[from_path]):\n",
    "        # Read the grayscale image\n",
    "        gray_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Denoise the grayscale image using fastNlMeansDenoising\n",
    "        # Adjust the h, templateWindowSize, and searchWindowSize parameters for better denoising\n",
    "        denoised_img = cv2.fastNlMeansDenoising(gray_img, None, h=10, templateWindowSize=7, searchWindowSize=21)\n",
    "\n",
    "        # Save the denoised image\n",
    "        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n",
    "        cv2.imwrite(save_path, denoised_img)\n",
    "\n",
    "    # Update the image paths in the DataFrame with the new denoised image paths\n",
    "    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### binarizing with local thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_threshold_images(df, from_path, new_dir_path, block_size, offset):\n",
    "    try:\n",
    "        os.makedirs(new_dir_path)\n",
    "    except:\n",
    "        pass\n",
    "    for i, img_path in enumerate(df[from_path]):\n",
    "        # Read the image in grayscale\n",
    "        gray_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Perform local thresholding using the threshold_local method from skimage\n",
    "        binary_img = threshold_local(gray_img, block_size, offset=offset, method='gaussian', mode='reflect', cval=0)\n",
    "\n",
    "        # Convert the binary image to uint8 format (0 or 255)\n",
    "        binary_img = (binary_img * 255).astype(np.uint8)\n",
    "\n",
    "        # Save the binary image\n",
    "        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n",
    "        cv2.imwrite(save_path, binary_img)\n",
    "\n",
    "    # Update the image paths in the DataFrame with the new binary image paths\n",
    "    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now binarizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_images(df, from_path, new_dir_path):\n",
    "    try:\n",
    "        os.makedirs(new_dir_path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for i, img_path in enumerate(df[from_path]):\n",
    "        # Read the image in grayscale\n",
    "        im = Image.open(img_path)\n",
    "        im = np.array(im)\n",
    "\n",
    "        # Apply binary thresholding using Otsu's method\n",
    "        _, binary_im = cv2.threshold(im, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        # Convert the binary image to PIL Image\n",
    "        binary_im = Image.fromarray(binary_im)\n",
    "\n",
    "        # Save the binary image\n",
    "        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n",
    "        binary_im.save(save_path)\n",
    "\n",
    "    # Update the image paths in the DataFrame with the new binary image paths\n",
    "    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inverting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_images(df, from_path, new_dir_path):\n",
    "    try:\n",
    "        os.makedirs(new_dir_path)\n",
    "    except:\n",
    "        pass\n",
    "    for i, img_path in enumerate(df[from_path]):\n",
    "        # Read the binarized image\n",
    "        bin_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Invert the image color using bitwise NOT operation\n",
    "        inverted_img = cv2.bitwise_not(bin_img)\n",
    "        \n",
    "        # Save the inverted image\n",
    "        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n",
    "        cv2.imwrite(save_path, inverted_img)\n",
    "    \n",
    "    # Update the image paths in the DataFrame with the new inverted image paths\n",
    "    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dilateing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate_images(df, from_path, new_dir_path):\n",
    "    try:\n",
    "        os.makedirs(new_dir_path)\n",
    "    except:\n",
    "        pass\n",
    "    for i, img_path in enumerate(df[from_path]):\n",
    "        # Read the inverted image\n",
    "        inverted_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Define the kernel for dilation (a 3x3 kernel in this case)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "        \n",
    "        # Dilate the image to increase the thickness of each digit\n",
    "        dilated_img = cv2.dilate(inverted_img, kernel, iterations=1)\n",
    "        \n",
    "        # Save the dilated image\n",
    "        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n",
    "        cv2.imwrite(save_path, dilated_img)\n",
    "    \n",
    "    # Update the image paths in the DataFrame with the new dilated image paths\n",
    "    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eroding images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erode_images(df, from_path, new_dir_path):\n",
    "    try:\n",
    "        os.makedirs(new_dir_path)\n",
    "    except:\n",
    "        pass\n",
    "    for i, img_path in enumerate(df[from_path]):\n",
    "        # Read the inverted image\n",
    "        inverted_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Define the kernel for erosion (a 3x3 kernel in this case)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "        \n",
    "        # Erode the image to reduce the thickness of each digit\n",
    "        eroded_img = cv2.erode(inverted_img, kernel, iterations=1)\n",
    "        \n",
    "        # Save the eroded image\n",
    "        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n",
    "        cv2.imwrite(save_path, eroded_img)\n",
    "    \n",
    "    # Update the image paths in the DataFrame with the new eroded image paths\n",
    "    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### thinning using skeletonize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thin_images(df, from_path, new_dir_path):\n",
    "    try:\n",
    "        os.makedirs(new_dir_path)\n",
    "    except:\n",
    "        pass\n",
    "    for i, img_path in enumerate(df[from_path]):\n",
    "        # Read the inverted image\n",
    "        inverted_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Binarize the image (needed for skeletonization)\n",
    "        _, binary_img = cv2.threshold(inverted_img, 128, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Perform skeletonization\n",
    "        skeleton = skeletonize(binary_img / 255)\n",
    "        \n",
    "        # Convert the skeleton back to uint8 format\n",
    "        thin_img = (skeleton * 255).astype(np.uint8)\n",
    "        \n",
    "        # Save the thinned image\n",
    "        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n",
    "        cv2.imwrite(save_path, thin_img)\n",
    "    \n",
    "    # Update the image paths in the DataFrame with the new thinned image paths\n",
    "    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### contour-based thinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thin_images(df, from_path, new_dir_path):\n",
    "    try:\n",
    "        os.makedirs(new_dir_path)\n",
    "    except:\n",
    "        pass\n",
    "    for i, img_path in enumerate(df[from_path]):\n",
    "        # Read the inverted image\n",
    "        inverted_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Binarize the image\n",
    "        _, binary_img = cv2.threshold(inverted_img, 128, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Find contours in the binary image\n",
    "        contours, _ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        \n",
    "        # Iterate through each contour and thin it\n",
    "        for contour in contours:\n",
    "            # Create a blank image to draw the contour\n",
    "            contour_img = np.zeros_like(binary_img)\n",
    "            cv2.drawContours(contour_img, [contour], -1, 255, thickness=cv2.FILLED)\n",
    "            \n",
    "            # Perform XOR operation to thin the contour\n",
    "            binary_img = cv2.bitwise_xor(binary_img, contour_img)\n",
    "        \n",
    "        # Save the thinned image\n",
    "        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n",
    "        cv2.imwrite(save_path, binary_img)\n",
    "    \n",
    "    # Update the image paths in the DataFrame with the new thinned image paths\n",
    "    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### edge detection with canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_edges_canny(df, from_path, new_dir_path, low_threshold, high_threshold):\n",
    "    try:\n",
    "        os.makedirs(new_dir_path)\n",
    "    except:\n",
    "        pass\n",
    "    for i, img_path in enumerate(df[from_path]):\n",
    "        # Read the image in grayscale\n",
    "        gray_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Apply Canny edge detection\n",
    "        edges = cv2.Canny(gray_img, low_threshold, high_threshold)\n",
    "        \n",
    "        # Save the edges image\n",
    "        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n",
    "        cv2.imwrite(save_path, edges)\n",
    "    \n",
    "    # Update the image paths in the DataFrame with the new edges image paths\n",
    "    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using MSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_digits_mser(df, from_path, new_dir_path, min_area=100, max_area=2000, max_variation=0.25, min_diversity=0.2):\n",
    "    try:\n",
    "        os.makedirs(new_dir_path)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    digits_counts = []\n",
    "    for i, img_path in enumerate(df[from_path]):\n",
    "        # Read the image in grayscale\n",
    "        gray_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Initialize MSER detector\n",
    "        mser = cv2.MSER_create(min_area=min_area, max_area=max_area, max_variation=max_variation, min_diversity=min_diversity)\n",
    "        \n",
    "        # Detect MSER regions\n",
    "        regions, _ = mser.detectRegions(gray_img)\n",
    "        \n",
    "        # Filter regions based on size and aspect ratio\n",
    "        digits_regions = []\n",
    "        for region in regions:\n",
    "            x, y, w, h = cv2.boundingRect(region)\n",
    "            aspect_ratio = w / float(h)\n",
    "            if 0.2 < aspect_ratio < 2.5 and min_area < w * h < max_area:\n",
    "                digits_regions.append(region)\n",
    "        \n",
    "        # Draw and save the regions\n",
    "        mser_img = gray_img.copy()\n",
    "        for region in digits_regions:\n",
    "            x, y, w, h = cv2.boundingRect(region)\n",
    "            cv2.rectangle(mser_img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        \n",
    "        # Save the image with MSER regions marked\n",
    "        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n",
    "        cv2.imwrite(save_path, mser_img)\n",
    "\n",
    "        # Saving new digits count \n",
    "        digits_counts.append(len(digits_regions))\n",
    "\n",
    "    # Update the image paths in the DataFrame with the new MSER images paths\n",
    "    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n",
    "    df[\"digits_count\"] = digits_counts\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using CCA for detecting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_digits_cca(df, from_path, new_dir_path):\n",
    "    try:\n",
    "        os.makedirs(new_dir_path)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    digits_counts = []\n",
    "    for i, img_path in enumerate(df[from_path]):\n",
    "        # Read the grayscale image\n",
    "        gray_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Threshold the image to binarize it (you may need to adjust the threshold value)\n",
    "        _, binary_img = cv2.threshold(gray_img, 128, 255, cv2.THRESH_BINARY_INV)\n",
    "        \n",
    "        # Perform connected component analysis\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_img)\n",
    "        \n",
    "        # Initialize the list to store the regions\n",
    "        digits_regions = []\n",
    "        \n",
    "        # Iterate over the connected components\n",
    "        for label in range(1, num_labels):\n",
    "            left, top, width, height, area = stats[label]\n",
    "            \n",
    "            # Apply additional filtering based on the area and aspect ratio of the component\n",
    "            min_area = 100  # Adjust this value based on your requirements\n",
    "            max_area = 2000  # Adjust this value based on your requirements\n",
    "            min_aspect_ratio = 0.2  # Adjust this value based on your requirements\n",
    "            max_aspect_ratio = 2.5  # Adjust this value based on your requirements\n",
    "            \n",
    "            if min_area < area < max_area and min_aspect_ratio < width / height < max_aspect_ratio:\n",
    "                digits_regions.append((left, top, width, height))\n",
    "        \n",
    "        # Draw and save the regions\n",
    "        cca_img = gray_img.copy()\n",
    "        for region in digits_regions:\n",
    "            left, top, width, height = region\n",
    "            cv2.rectangle(cca_img, (left, top), (left + width, top + height), (255, 0, 0), 2)\n",
    "        \n",
    "        # Save the image with CCA regions marked\n",
    "        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n",
    "        cv2.imwrite(save_path, cca_img)\n",
    "\n",
    "        # Saving new digits count \n",
    "        digits_counts.append(len(digits_regions))\n",
    "\n",
    "    # Update the image paths in the DataFrame with the new CCA images paths\n",
    "    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n",
    "    df[\"digits_count\"] = digits_counts\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_digits_with_vertical_lines(df, from_path, new_dir_path):\n",
    "    try:\n",
    "        os.makedirs(new_dir_path)\n",
    "    except:\n",
    "        pass\n",
    "    digit_column = []\n",
    "    for i, img_path in enumerate(df[from_path]):\n",
    "        # Read the image in grayscale\n",
    "        gray_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        digit_count = 1\n",
    "        # Create a copy of the image to apply changes\n",
    "        modified_img = gray_img.copy()\n",
    "\n",
    "        # Find columns with all pixel values equal to 0 and replace them with 0.5\n",
    "        empty_columns = (gray_img.sum(axis=0) < 0)\n",
    "        column_diff = empty_columns[1:] ^ empty_columns[:-1]  # Calculate the difference between consecutive empty columns using XOR\n",
    "        column_diff = [10] + column_diff.tolist() + [10]  # Add padding to the differences to handle edge cases\n",
    "        for idx, diff in enumerate(column_diff[:-1]):\n",
    "            if diff == 1 and column_diff[idx + 1] == 1:  # Check if two consecutive columns are too close\n",
    "                modified_img[:, idx] = 128  # Set the column to 0.5 (gray)\n",
    "                # Draw a vertical line on the modified image\n",
    "                cv2.line(modified_img, (idx, 0), (idx, gray_img.shape[0]), (0, 0, 255), 2)\n",
    "\n",
    "        # Find the column sums of the binary image\n",
    "        column_sums = modified_img.sum(axis=0)\n",
    "\n",
    "        # Identify the columns where there are no pixel values with 1\n",
    "        column_separator = [idx for idx, val in enumerate(column_sums) if val == 0]\n",
    "\n",
    "        # Add the start and end column indices to the separators\n",
    "        column_separator = [0] + column_separator + [gray_img.shape[1]]\n",
    "        # Crop the individual digits using the separators\n",
    "        for idx in range(len(column_separator) - 1):\n",
    "            start_col = column_separator[idx]\n",
    "            end_col = column_separator[idx + 1]\n",
    "\n",
    "            # Crop and save the digit only if it is not empty and the width is greater than 10 pixels\n",
    "            digit_img = gray_img[:, start_col:end_col]\n",
    "            if not cv2.countNonZero(digit_img) == 0 and end_col - start_col > 0 and end_col+1 < modified_img.shape[1]:\n",
    "                digit_count += 1\n",
    "                modified_img[:, end_col+1] = 128 \n",
    "        digit_column.append(digit_count)\n",
    "        # Save the image with CCA regions marked (with lines added)\n",
    "        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n",
    "        cv2.imwrite(save_path, modified_img)\n",
    "    df[\"digits_count\"] = digit_column\n",
    "    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_digits_contours(df, from_path, new_dir_path, min_area=100, max_area=2000, min_aspect_ratio=0.2, max_aspect_ratio=2.5):\n",
    "    try:\n",
    "        os.makedirs(new_dir_path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    digits_counts = []\n",
    "    for i, img_path in enumerate(df[from_path]):\n",
    "        # Read the image in grayscale\n",
    "        gray_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Threshold the image to create a binary image\n",
    "        _, binary_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "        # Find contours in the binary image\n",
    "        contours, _ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Filter contours based on size and aspect ratio\n",
    "        digits_contours = []\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            aspect_ratio = w / float(h)\n",
    "            if min_area < w * h < max_area and min_aspect_ratio < aspect_ratio < max_aspect_ratio:\n",
    "                digits_contours.append(contour)\n",
    "\n",
    "        # Draw and save the contours\n",
    "        contour_img = gray_img.copy()\n",
    "        cv2.drawContours(contour_img, digits_contours, -1, (255, 0, 0), 2)\n",
    "\n",
    "        # Save the image with contours marked\n",
    "        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n",
    "        cv2.imwrite(save_path, contour_img)\n",
    "\n",
    "        # Saving new digits count\n",
    "        digits_counts.append(len(digits_contours))\n",
    "\n",
    "    # Update the image paths in the DataFrame with the new images paths\n",
    "    df[\"digits_count\"] = digits_counts\n",
    "    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_digits_sift(df, from_path, new_dir_path):\n",
    "    try:\n",
    "        os.makedirs(new_dir_path)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    digits_counts = []\n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    for i, img_path in enumerate(df[from_path]):\n",
    "        # Read the image in grayscale\n",
    "        gray_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Detect keypoints and descriptors using SIFT\n",
    "        keypoints, descriptors = sift.detectAndCompute(gray_img, None)\n",
    "        \n",
    "        # Draw keypoints on the image\n",
    "        sift_img = cv2.drawKeypoints(gray_img, keypoints, None)\n",
    "        \n",
    "        # Save the image with SIFT keypoints marked\n",
    "        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n",
    "        cv2.imwrite(save_path, sift_img)\n",
    "\n",
    "        # Saving new digits count (you can adjust this based on the detected keypoints)\n",
    "        digits_counts.append(len(keypoints))\n",
    "\n",
    "    # Update the image paths in the DataFrame with the new SIFT images paths\n",
    "    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n",
    "    df[\"digits_count\"] = digits_counts\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(df,from_path, new_dir_path, target_height):\n",
    "    try:\n",
    "        os.makedirs(new_dir_path)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for i, img_path in enumerate(df[from_path]):\n",
    "        # Read the image\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Calculate the target width to maintain the aspect ratio\n",
    "        height, width = img.shape\n",
    "        target_width = int(width * (target_height / height))\n",
    "        \n",
    "        # Resize the image\n",
    "        resized_img = cv2.resize(img, (target_width, target_height))\n",
    "        \n",
    "        # Save the resized image\n",
    "        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n",
    "        cv2.imwrite(save_path, resized_img)\n",
    "    \n",
    "    # Update the image paths in the DataFrame with the new resized image paths\n",
    "    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_white_padding(df,from_path,new_dir_path, padding_width):\n",
    "    try:\n",
    "        os.makedirs(new_dir_path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for i, img_path in enumerate(df[from_path]):\n",
    "        # Read the resized image\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Calculate the new width with padding\n",
    "        height, width = img.shape\n",
    "        new_width = width + 2 * padding_width\n",
    "\n",
    "        # Create a new blank white image with the desired width and height\n",
    "        padded_img = 255 * np.ones((height, new_width), dtype=np.uint8)\n",
    "\n",
    "        # Calculate the starting column to paste the resized image\n",
    "        start_col = padding_width\n",
    "\n",
    "        # Paste the resized image onto the new blank image\n",
    "        padded_img[:, start_col:start_col + width] = img\n",
    "\n",
    "        # Save the padded image\n",
    "        save_path = os.path.join(new_dir_path, f\"{i:05d}.png\")\n",
    "        cv2.imwrite(save_path, padded_img)\n",
    "\n",
    "    # Update the image paths in the DataFrame with the new padded image paths\n",
    "    df[new_dir_path] = [os.path.join(new_dir_path, f\"{i:05d}.png\") for i in range(len(df))]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11719\n",
      "11719\n"
     ]
    }
   ],
   "source": [
    "all_labels = reset_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 1000\n",
      "target: ./padded/00022.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_random_image(all_labels,'./padded/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preproccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = convert_to_grayscale(all_labels,'image_path','./grayscaled/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_height = 28\n",
    "all_labels = resize_images(all_labels,'./grayscaled/', './resized/', target_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_width = 28\n",
    "all_labels = add_white_padding(all_labels, './resized/','./padded/', padding_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_labels = denoise_images(all_labels, 'image_path', './denoised/')\n",
    "all_labels = denoise_images_fastnlmeans(all_labels, './grayscaled/', './denoised_fastnlmeans/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_size = 9\n",
    "# offset = 0\n",
    "# all_labels = local_threshold_images(all_labels, './edges/', './local_thresholded/', block_size, offset)\n",
    "all_labels = binarize_images(all_labels, './denoised_fastnlmeans/', './binarized/')\n",
    "all_labels = invert_images(all_labels, './denoised_fastnlmeans/', './inverted/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_labels = dilate_images(all_labels, './edges/', './dilated/')\n",
    "all_labels = erode_images(all_labels, './inverted/', './eroded/')\n",
    "all_labels = thin_images(all_labels, './inverted/', './thinned/')\n",
    "all_labels = thin_images(all_labels, './inverted/', './c_thinned/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_threshold = 50\n",
    "high_threshold = 150\n",
    "all_labels = detect_edges_canny(all_labels, './denoised_fastnlmeans/', './edges/', low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_area = 300\n",
    "max_area = 3000\n",
    "max_variation = 0.5\n",
    "min_diversity = 0.5\n",
    "all_labels = detect_digits_mser(all_labels, './grayscaled/', './mser/', min_area, max_area, max_variation, min_diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = detect_digits_cca(all_labels, 'image_path', './cca/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = separate_digits_with_vertical_lines(all_labels, 'image_path', './vertical_lines/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_area = 100\n",
    "max_area = 2000\n",
    "min_aspect_ratio = 0.2\n",
    "max_aspect_ratio = 2.5\n",
    "all_labels = detect_digits_contours(all_labels, 'image_path', './contours/', min_area, max_area, min_aspect_ratio, max_aspect_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = detect_digits_sift(all_labels, 'image_path', './sift/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 389 \n",
      "Accuracy: 0.033193958528884716\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = (all_labels[\"actual_digit_count\"] == all_labels[\"digits_count\"]).sum()\n",
    "accuracy = correct_predictions / len(all_labels)\n",
    "print(\"Correct:\", correct_predictions, \"\\nAccuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>actual_digit_count</th>\n",
       "      <th>./grayscaled/</th>\n",
       "      <th>./resized/</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>1500</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00000.png</td>\n",
       "      <td>./resized/00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>5743</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00001.png</td>\n",
       "      <td>./resized/00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>1056</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00002.png</td>\n",
       "      <td>./resized/00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00003.png</td>\n",
       "      <td>./resized/00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00004.png</td>\n",
       "      <td>./resized/00004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path label  \\\n",
       "0  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...  1500   \n",
       "1  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...  5743   \n",
       "2  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...  1056   \n",
       "3  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...  1000   \n",
       "4  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...  1000   \n",
       "\n",
       "   actual_digit_count           ./grayscaled/           ./resized/  \n",
       "0                   4  ./grayscaled/00000.png  ./resized/00000.png  \n",
       "1                   4  ./grayscaled/00001.png  ./resized/00001.png  \n",
       "2                   4  ./grayscaled/00002.png  ./resized/00002.png  \n",
       "3                   4  ./grayscaled/00003.png  ./resized/00003.png  \n",
       "4                   4  ./grayscaled/00004.png  ./resized/00004.png  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST segmentation :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 0.1462 - accuracy: 0.9563 - val_loss: 0.0507 - val_accuracy: 0.9829\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 15s 12ms/step - loss: 0.0448 - accuracy: 0.9860 - val_loss: 0.0370 - val_accuracy: 0.9875\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 15s 12ms/step - loss: 0.0304 - accuracy: 0.9901 - val_loss: 0.0331 - val_accuracy: 0.9885\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 0.0226 - accuracy: 0.9926 - val_loss: 0.0346 - val_accuracy: 0.9892\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 15s 13ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.0236 - val_accuracy: 0.9929\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 15s 13ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.0274 - val_accuracy: 0.9922\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 15s 13ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0290 - val_accuracy: 0.9917\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 15s 12ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.0258 - val_accuracy: 0.9939\n",
      "Epoch 9/10\n",
      "1200/1200 [==============================] - 15s 12ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0304 - val_accuracy: 0.9912\n",
      "Epoch 10/10\n",
      "1200/1200 [==============================] - 15s 12ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.0319 - val_accuracy: 0.9921\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 13, 13, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               204928    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225034 (879.04 KB)\n",
      "Trainable params: 225034 (879.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajab\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "x_train = train_images.reshape(60000, 28, 28, 1) / 255\n",
    "x_test = test_images.reshape(10000, 28, 28, 1) / 255\n",
    "y_train = to_categorical(train_labels)\n",
    "y_test = to_categorical(test_labels)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=50)\n",
    "model.save('mnist_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple method that search in images by mnist model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def predict_multi_digits_sliding_window(model, image_path, window_size=(28, 28), threshold=0.80,digit_width=10):\n",
    "    try:\n",
    "        os.makedirs(new_dir_path)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = img / 255.0  # Normalize the entire image\n",
    "    image_height, image_width = img.shape\n",
    "    digits = []  # List to store detected digits\n",
    "    col_end = 28\n",
    "    while col_end <= image_width:\n",
    "        col_start = col_end - 28\n",
    "        window = img[:, col_start:col_end]\n",
    "        \n",
    "        # Predict using the model\n",
    "        predictions = model.predict(window.reshape(1, 28, 28, 1),verbose=0)\n",
    "        predicted_label = np.argmax(predictions)\n",
    "        max_probability = np.max(predictions)\n",
    "        #print(f\"predict in {col_start} to {col_end} : \",predictions,'  -->',predicted_label,'  ---->',max_probability)\n",
    "        \n",
    "        if max_probability > threshold:\n",
    "            digits.append(str(predicted_label))\n",
    "            col_end += digit_width\n",
    "        \n",
    "        col_end+=1\n",
    "    if digits == [] : return \"0\"\n",
    "    return \"\".join(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|| 50/50 [00:54<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 54.6115837097168 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "predicted_labels = []\n",
    "digits_count = []\n",
    "\n",
    "# Create a new DataFrame for the first 50 images\n",
    "limited_labels = all_labels.iloc[:50].copy()\n",
    "\n",
    "for image_path in tqdm(limited_labels['./resized/'], desc=\"Processing Images\"):\n",
    "    detected_digits = predict_multi_digits_sliding_window(model, image_path, new_dir_path)\n",
    "    predicted_labels.append(detected_digits)\n",
    "    digits_count.append(len(detected_digits))\n",
    "\n",
    "# Add the new columns to the limited_labels DataFrame\n",
    "limited_labels[\"predicted_labels\"] = predicted_labels\n",
    "limited_labels[\"digits_count\"] = digits_count\n",
    "\n",
    "# Concatenate the limited_labels DataFrame with the original all_labels DataFrame\n",
    "all_labels = pd.concat([limited_labels,all_labels.iloc[50:]], ignore_index=True)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(\"Execution time:\", execution_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "predicted_labels = []\n",
    "digits_count = []\n",
    "\n",
    "for image_path in tqdm(all_labels['./resized/'][:50], desc=\"Processing Images\"):\n",
    "    detected_digits = predict_multi_digits_sliding_window(model, image_path, new_dir_path)\n",
    "    predicted_labels.append(detected_digits)\n",
    "    digits_count.append(len(detected_digits))\n",
    "\n",
    "all_labels[\"predicted_labels\"] = predicted_labels\n",
    "all_labels[\"digits_count\"] = digits_count\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(\"Execution time:\", execution_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>actual_digit_count</th>\n",
       "      <th>./grayscaled/</th>\n",
       "      <th>./resized/</th>\n",
       "      <th>predicted_labels</th>\n",
       "      <th>digits_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>1500</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00000.png</td>\n",
       "      <td>./resized/00000.png</td>\n",
       "      <td>0627</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>5743</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00001.png</td>\n",
       "      <td>./resized/00001.png</td>\n",
       "      <td>57</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>1056</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00002.png</td>\n",
       "      <td>./resized/00002.png</td>\n",
       "      <td>652</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00003.png</td>\n",
       "      <td>./resized/00003.png</td>\n",
       "      <td>2226262</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00004.png</td>\n",
       "      <td>./resized/00004.png</td>\n",
       "      <td>702</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>2800</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00005.png</td>\n",
       "      <td>./resized/00005.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>1480</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00006.png</td>\n",
       "      <td>./resized/00006.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>3600</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00007.png</td>\n",
       "      <td>./resized/00007.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>./grayscaled/00008.png</td>\n",
       "      <td>./resized/00008.png</td>\n",
       "      <td>22</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00009.png</td>\n",
       "      <td>./resized/00009.png</td>\n",
       "      <td>32</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>8548</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00010.png</td>\n",
       "      <td>./resized/00010.png</td>\n",
       "      <td>22</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>20000</td>\n",
       "      <td>5</td>\n",
       "      <td>./grayscaled/00011.png</td>\n",
       "      <td>./resized/00011.png</td>\n",
       "      <td>2253</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>38117</td>\n",
       "      <td>5</td>\n",
       "      <td>./grayscaled/00012.png</td>\n",
       "      <td>./resized/00012.png</td>\n",
       "      <td>826</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>2500</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00013.png</td>\n",
       "      <td>./resized/00013.png</td>\n",
       "      <td>252</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>530</td>\n",
       "      <td>3</td>\n",
       "      <td>./grayscaled/00014.png</td>\n",
       "      <td>./resized/00014.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>1990</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00015.png</td>\n",
       "      <td>./resized/00015.png</td>\n",
       "      <td>22</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>230</td>\n",
       "      <td>3</td>\n",
       "      <td>./grayscaled/00016.png</td>\n",
       "      <td>./resized/00016.png</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>676</td>\n",
       "      <td>3</td>\n",
       "      <td>./grayscaled/00017.png</td>\n",
       "      <td>./resized/00017.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>./grayscaled/00018.png</td>\n",
       "      <td>./resized/00018.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>219</td>\n",
       "      <td>3</td>\n",
       "      <td>./grayscaled/00019.png</td>\n",
       "      <td>./resized/00019.png</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>2650</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00020.png</td>\n",
       "      <td>./resized/00020.png</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>./grayscaled/00021.png</td>\n",
       "      <td>./resized/00021.png</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00022.png</td>\n",
       "      <td>./resized/00022.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>960</td>\n",
       "      <td>3</td>\n",
       "      <td>./grayscaled/00023.png</td>\n",
       "      <td>./resized/00023.png</td>\n",
       "      <td>527</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>3200</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00024.png</td>\n",
       "      <td>./resized/00024.png</td>\n",
       "      <td>266</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>970</td>\n",
       "      <td>3</td>\n",
       "      <td>./grayscaled/00025.png</td>\n",
       "      <td>./resized/00025.png</td>\n",
       "      <td>72</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00026.png</td>\n",
       "      <td>./resized/00026.png</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>2590</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00027.png</td>\n",
       "      <td>./resized/00027.png</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>10000</td>\n",
       "      <td>5</td>\n",
       "      <td>./grayscaled/00028.png</td>\n",
       "      <td>./resized/00028.png</td>\n",
       "      <td>025</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>5500</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00029.png</td>\n",
       "      <td>./resized/00029.png</td>\n",
       "      <td>3632</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>3500</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00030.png</td>\n",
       "      <td>./resized/00030.png</td>\n",
       "      <td>522</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>244</td>\n",
       "      <td>3</td>\n",
       "      <td>./grayscaled/00031.png</td>\n",
       "      <td>./resized/00031.png</td>\n",
       "      <td>223</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>510</td>\n",
       "      <td>3</td>\n",
       "      <td>./grayscaled/00032.png</td>\n",
       "      <td>./resized/00032.png</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>./grayscaled/00033.png</td>\n",
       "      <td>./resized/00033.png</td>\n",
       "      <td>62</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>129</td>\n",
       "      <td>3</td>\n",
       "      <td>./grayscaled/00034.png</td>\n",
       "      <td>./resized/00034.png</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>./grayscaled/00035.png</td>\n",
       "      <td>./resized/00035.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>./grayscaled/00036.png</td>\n",
       "      <td>./resized/00036.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>62368</td>\n",
       "      <td>5</td>\n",
       "      <td>./grayscaled/00037.png</td>\n",
       "      <td>./resized/00037.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>154</td>\n",
       "      <td>3</td>\n",
       "      <td>./grayscaled/00038.png</td>\n",
       "      <td>./resized/00038.png</td>\n",
       "      <td>65</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>5605</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00039.png</td>\n",
       "      <td>./resized/00039.png</td>\n",
       "      <td>6225</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>./grayscaled/00040.png</td>\n",
       "      <td>./resized/00040.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>29305</td>\n",
       "      <td>5</td>\n",
       "      <td>./grayscaled/00041.png</td>\n",
       "      <td>./resized/00041.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>15000</td>\n",
       "      <td>5</td>\n",
       "      <td>./grayscaled/00042.png</td>\n",
       "      <td>./resized/00042.png</td>\n",
       "      <td>632</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>3818</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00043.png</td>\n",
       "      <td>./resized/00043.png</td>\n",
       "      <td>2223</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>5000</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00044.png</td>\n",
       "      <td>./resized/00044.png</td>\n",
       "      <td>22</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>50000</td>\n",
       "      <td>5</td>\n",
       "      <td>./grayscaled/00045.png</td>\n",
       "      <td>./resized/00045.png</td>\n",
       "      <td>22</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>285</td>\n",
       "      <td>3</td>\n",
       "      <td>./grayscaled/00046.png</td>\n",
       "      <td>./resized/00046.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>3172</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00047.png</td>\n",
       "      <td>./resized/00047.png</td>\n",
       "      <td>022</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>17000</td>\n",
       "      <td>5</td>\n",
       "      <td>./grayscaled/00048.png</td>\n",
       "      <td>./resized/00048.png</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...</td>\n",
       "      <td>2390</td>\n",
       "      <td>4</td>\n",
       "      <td>./grayscaled/00049.png</td>\n",
       "      <td>./resized/00049.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           image_path  label  \\\n",
       "0   ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   1500   \n",
       "1   ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   5743   \n",
       "2   ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   1056   \n",
       "3   ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   1000   \n",
       "4   ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   1000   \n",
       "5   ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   2800   \n",
       "6   ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   1480   \n",
       "7   ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   3600   \n",
       "8   ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...    300   \n",
       "9   ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   3000   \n",
       "10  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   8548   \n",
       "11  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...  20000   \n",
       "12  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...  38117   \n",
       "13  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   2500   \n",
       "14  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...    530   \n",
       "15  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   1990   \n",
       "16  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...    230   \n",
       "17  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...    676   \n",
       "18  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...    109   \n",
       "19  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...    219   \n",
       "20  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   2650   \n",
       "21  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...     63   \n",
       "22  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   1000   \n",
       "23  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...    960   \n",
       "24  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   3200   \n",
       "25  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...    970   \n",
       "26  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   1000   \n",
       "27  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   2590   \n",
       "28  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...  10000   \n",
       "29  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   5500   \n",
       "30  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   3500   \n",
       "31  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...    244   \n",
       "32  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...    510   \n",
       "33  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...    103   \n",
       "34  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...    129   \n",
       "35  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...     73   \n",
       "36  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...    107   \n",
       "37  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...  62368   \n",
       "38  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...    154   \n",
       "39  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   5605   \n",
       "40  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...     97   \n",
       "41  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...  29305   \n",
       "42  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...  15000   \n",
       "43  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   3818   \n",
       "44  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   5000   \n",
       "45  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...  50000   \n",
       "46  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...    285   \n",
       "47  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   3172   \n",
       "48  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...  17000   \n",
       "49  ./ORAND-CAR-2014/CAR-A/a_test_images/a_car_007...   2390   \n",
       "\n",
       "    actual_digit_count           ./grayscaled/           ./resized/  \\\n",
       "0                    4  ./grayscaled/00000.png  ./resized/00000.png   \n",
       "1                    4  ./grayscaled/00001.png  ./resized/00001.png   \n",
       "2                    4  ./grayscaled/00002.png  ./resized/00002.png   \n",
       "3                    4  ./grayscaled/00003.png  ./resized/00003.png   \n",
       "4                    4  ./grayscaled/00004.png  ./resized/00004.png   \n",
       "5                    4  ./grayscaled/00005.png  ./resized/00005.png   \n",
       "6                    4  ./grayscaled/00006.png  ./resized/00006.png   \n",
       "7                    4  ./grayscaled/00007.png  ./resized/00007.png   \n",
       "8                    3  ./grayscaled/00008.png  ./resized/00008.png   \n",
       "9                    4  ./grayscaled/00009.png  ./resized/00009.png   \n",
       "10                   4  ./grayscaled/00010.png  ./resized/00010.png   \n",
       "11                   5  ./grayscaled/00011.png  ./resized/00011.png   \n",
       "12                   5  ./grayscaled/00012.png  ./resized/00012.png   \n",
       "13                   4  ./grayscaled/00013.png  ./resized/00013.png   \n",
       "14                   3  ./grayscaled/00014.png  ./resized/00014.png   \n",
       "15                   4  ./grayscaled/00015.png  ./resized/00015.png   \n",
       "16                   3  ./grayscaled/00016.png  ./resized/00016.png   \n",
       "17                   3  ./grayscaled/00017.png  ./resized/00017.png   \n",
       "18                   3  ./grayscaled/00018.png  ./resized/00018.png   \n",
       "19                   3  ./grayscaled/00019.png  ./resized/00019.png   \n",
       "20                   4  ./grayscaled/00020.png  ./resized/00020.png   \n",
       "21                   2  ./grayscaled/00021.png  ./resized/00021.png   \n",
       "22                   4  ./grayscaled/00022.png  ./resized/00022.png   \n",
       "23                   3  ./grayscaled/00023.png  ./resized/00023.png   \n",
       "24                   4  ./grayscaled/00024.png  ./resized/00024.png   \n",
       "25                   3  ./grayscaled/00025.png  ./resized/00025.png   \n",
       "26                   4  ./grayscaled/00026.png  ./resized/00026.png   \n",
       "27                   4  ./grayscaled/00027.png  ./resized/00027.png   \n",
       "28                   5  ./grayscaled/00028.png  ./resized/00028.png   \n",
       "29                   4  ./grayscaled/00029.png  ./resized/00029.png   \n",
       "30                   4  ./grayscaled/00030.png  ./resized/00030.png   \n",
       "31                   3  ./grayscaled/00031.png  ./resized/00031.png   \n",
       "32                   3  ./grayscaled/00032.png  ./resized/00032.png   \n",
       "33                   3  ./grayscaled/00033.png  ./resized/00033.png   \n",
       "34                   3  ./grayscaled/00034.png  ./resized/00034.png   \n",
       "35                   2  ./grayscaled/00035.png  ./resized/00035.png   \n",
       "36                   3  ./grayscaled/00036.png  ./resized/00036.png   \n",
       "37                   5  ./grayscaled/00037.png  ./resized/00037.png   \n",
       "38                   3  ./grayscaled/00038.png  ./resized/00038.png   \n",
       "39                   4  ./grayscaled/00039.png  ./resized/00039.png   \n",
       "40                   2  ./grayscaled/00040.png  ./resized/00040.png   \n",
       "41                   5  ./grayscaled/00041.png  ./resized/00041.png   \n",
       "42                   5  ./grayscaled/00042.png  ./resized/00042.png   \n",
       "43                   4  ./grayscaled/00043.png  ./resized/00043.png   \n",
       "44                   4  ./grayscaled/00044.png  ./resized/00044.png   \n",
       "45                   5  ./grayscaled/00045.png  ./resized/00045.png   \n",
       "46                   3  ./grayscaled/00046.png  ./resized/00046.png   \n",
       "47                   4  ./grayscaled/00047.png  ./resized/00047.png   \n",
       "48                   5  ./grayscaled/00048.png  ./resized/00048.png   \n",
       "49                   4  ./grayscaled/00049.png  ./resized/00049.png   \n",
       "\n",
       "   predicted_labels  digits_count  \n",
       "0              0627           4.0  \n",
       "1                57           2.0  \n",
       "2               652           3.0  \n",
       "3           2226262           7.0  \n",
       "4               702           3.0  \n",
       "5                 0           1.0  \n",
       "6                 0           1.0  \n",
       "7                 0           1.0  \n",
       "8                22           2.0  \n",
       "9                32           2.0  \n",
       "10               22           2.0  \n",
       "11             2253           4.0  \n",
       "12              826           3.0  \n",
       "13              252           3.0  \n",
       "14                0           1.0  \n",
       "15               22           2.0  \n",
       "16                6           1.0  \n",
       "17                0           1.0  \n",
       "18                0           1.0  \n",
       "19                4           1.0  \n",
       "20                2           1.0  \n",
       "21                5           1.0  \n",
       "22                0           1.0  \n",
       "23              527           3.0  \n",
       "24              266           3.0  \n",
       "25               72           2.0  \n",
       "26                2           1.0  \n",
       "27                6           1.0  \n",
       "28              025           3.0  \n",
       "29             3632           4.0  \n",
       "30              522           3.0  \n",
       "31              223           3.0  \n",
       "32                7           1.0  \n",
       "33               62           2.0  \n",
       "34                3           1.0  \n",
       "35                0           1.0  \n",
       "36                0           1.0  \n",
       "37                0           1.0  \n",
       "38               65           2.0  \n",
       "39             6225           4.0  \n",
       "40                0           1.0  \n",
       "41                0           1.0  \n",
       "42              632           3.0  \n",
       "43             2223           4.0  \n",
       "44               22           2.0  \n",
       "45               22           2.0  \n",
       "46                0           1.0  \n",
       "47              022           3.0  \n",
       "48                2           1.0  \n",
       "49                0           1.0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### measuring count of digits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = (all_labels[\"actual_digit_count\"] == all_labels[\"digits_count\"]).sum()\n",
    "accuracy = correct_predictions / len(all_labels)\n",
    "print(\"Correct:\", correct_predictions, \"\\nAccuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### measuring exact matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = (all_labels[\"label\"] == all_labels[\"predicted_labels\"]).sum()\n",
    "accuracy = correct_predictions / len(all_labels)\n",
    "print(\"Correct:\", correct_predictions, \"\\nAccuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
